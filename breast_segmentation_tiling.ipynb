{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical-Optimized Breast Tissue Segmentation and BYOL Augmentation Demo\n",
    "\n",
    "This notebook demonstrates the medical-optimized breast tissue segmentation and BYOL augmentations implemented in `train_byol_mammo.py`. Shows tiles, frequency energy detection for micro-calcifications, and medical-appropriate transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d428a141c10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from skimage import morphology, measure, filters\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Import BYOL transforms\n",
    "from lightly.transforms.byol_transform import BYOLTransform\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration - AGGRESSIVE background rejection\nDATA_DIR = Path(\"./split_images/training\")\nTILE_SIZE = 256\nTILE_STRIDE = 128\nNUM_SAMPLES = 10\nMIN_BREAST_RATIO = 0.15  # INCREASED: More strict breast tissue requirement\nMIN_FREQ_ENERGY = 0.03   # INCREASED: Much higher threshold\nMIN_BREAST_FOR_FREQ = 0.12  # INCREASED: Even more breast tissue required for frequency selection\nMIN_TILE_INTENSITY = 40  # NEW: Minimum average intensity to avoid background\nMIN_NON_ZERO_PIXELS = 0.7  # NEW: At least 70% of pixels must be non-background"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compute_frequency_energy(image_patch: np.ndarray) -> float:\n    \"\"\"\n    Compute high-frequency energy with AGGRESSIVE background rejection\n    \"\"\"\n    if len(image_patch.shape) == 3:\n        gray = cv2.cvtColor(image_patch, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image_patch.copy()\n    \n    # AGGRESSIVE background rejection\n    mean_intensity = np.mean(gray)\n    if mean_intensity < MIN_TILE_INTENSITY:  # Much stricter intensity threshold\n        return 0.0\n    \n    # Check for sufficient non-background pixels\n    non_zero_ratio = np.sum(gray > 15) / gray.size\n    if non_zero_ratio < MIN_NON_ZERO_PIXELS:  # Too much background\n        return 0.0\n    \n    # Apply Laplacian of Gaussian for high-frequency detection\n    blurred = cv2.GaussianBlur(gray.astype(np.float32), (3, 3), 1.0)\n    laplacian = cv2.Laplacian(blurred, cv2.CV_32F, ksize=3)\n    \n    # Focus only on positive responses (bright spots)\n    positive_laplacian = np.maximum(laplacian, 0)\n    \n    # Only analyze pixels with meaningful intensity\n    mask = gray > max(30, mean_intensity * 0.4)  # Much stricter tissue mask\n    if np.sum(mask) < (gray.size * 0.2):  # Need substantial tissue content\n        return 0.0\n    \n    masked_laplacian = positive_laplacian[mask]\n    energy = np.var(masked_laplacian) / (mean_intensity + 1e-8)\n    \n    return float(energy)\n\n\ndef is_background_tile(image_patch: np.ndarray) -> bool:\n    \"\"\"\n    Comprehensive background detection to reject empty/dark tiles\n    \"\"\"\n    if len(image_patch.shape) == 3:\n        gray = cv2.cvtColor(image_patch, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image_patch.copy()\n    \n    # Multiple background rejection criteria\n    mean_intensity = np.mean(gray)\n    std_intensity = np.std(gray)\n    non_zero_pixels = np.sum(gray > 15)\n    total_pixels = gray.size\n    \n    # Criteria for background tiles:\n    # 1. Too dark overall\n    if mean_intensity < MIN_TILE_INTENSITY:\n        return True\n    \n    # 2. Too many near-zero pixels (empty space)\n    if non_zero_pixels / total_pixels < MIN_NON_ZERO_PIXELS:\n        return True\n    \n    # 3. Very low variation (uniform background)\n    if std_intensity < 10:\n        return True\n    \n    # 4. Check intensity distribution - reject if too skewed toward zero\n    histogram, _ = np.histogram(gray, bins=50, range=(0, 255))\n    if histogram[0] > total_pixels * 0.3:  # More than 30% pixels near zero\n        return True\n    \n    return False\n\n\ndef segment_breast_tissue(image_array: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Enhanced breast tissue segmentation with aggressive background removal\n    \"\"\"\n    if len(image_array.shape) == 3:\n        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n    else:\n        gray = image_array.copy()\n    \n    # More aggressive pre-filtering of background\n    filtered_gray = np.where(gray > 20, gray, 0)  # Stricter background cutoff\n    \n    # Otsu thresholding\n    _, binary = cv2.threshold(filtered_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    \n    # Additional background removal based on intensity\n    binary = np.where(gray > 25, binary, 0).astype(np.uint8)\n    \n    # More aggressive morphological operations\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # Larger kernel\n    opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n    \n    # Fill holes\n    filled = ndimage.binary_fill_holes(opened).astype(np.uint8) * 255\n    \n    # Keep largest connected component\n    num_labels, labels = cv2.connectedComponents(filled)\n    if num_labels > 1:\n        largest_label = 1 + np.argmax([np.sum(labels == i) for i in range(1, num_labels)])\n        mask = (labels == largest_label).astype(np.uint8) * 255\n    else:\n        mask = filled\n    \n    # Closing with larger kernel for smoother boundaries\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask > 0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_breast_tiles_with_freq_energy(image_array, breast_mask, tile_size, stride, \n                                          min_breast_ratio=0.15, min_freq_energy=0.03, min_breast_for_freq=0.12):\n    \"\"\"\n    Extract tiles with AGGRESSIVE background rejection - NO empty space tiles allowed\n    \"\"\"\n    height, width = image_array.shape[:2]\n    tiles = []\n    rejected_background = 0\n    rejected_intensity = 0\n    rejected_breast_ratio = 0\n    rejected_freq_energy = 0\n    \n    # Generate all possible tile positions\n    y_positions = list(range(0, max(1, height - tile_size + 1), stride))\n    x_positions = list(range(0, max(1, width - tile_size + 1), stride))\n    \n    # Add edge positions if needed\n    if y_positions[-1] + tile_size < height:\n        y_positions.append(height - tile_size)\n    if x_positions[-1] + tile_size < width:\n        x_positions.append(width - tile_size)\n    \n    for y in y_positions:\n        for x in x_positions:\n            # Extract image tile\n            tile_image = image_array[y:y+tile_size, x:x+tile_size]\n            \n            # STEP 1: Comprehensive background rejection\n            if is_background_tile(tile_image):\n                rejected_background += 1\n                continue\n            \n            # STEP 2: Intensity-based rejection\n            mean_intensity = np.mean(tile_image)\n            if mean_intensity < MIN_TILE_INTENSITY:\n                rejected_intensity += 1\n                continue\n            \n            # STEP 3: Breast tissue ratio check\n            tile_mask = breast_mask[y:y+tile_size, x:x+tile_size]\n            breast_ratio = np.sum(tile_mask) / (tile_size * tile_size)\n            \n            # STEP 4: Enhanced selection logic with multiple criteria\n            freq_energy = compute_frequency_energy(tile_image)\n            \n            # Main selection criteria\n            selected = False\n            selection_reason = \"\"\n            \n            if breast_ratio >= min_breast_ratio:\n                selected = True\n                selection_reason = \"breast_tissue\"\n            elif (freq_energy >= min_freq_energy and \n                  breast_ratio >= min_breast_for_freq and \n                  mean_intensity >= MIN_TILE_INTENSITY + 10):  # Even stricter for freq tiles\n                selected = True\n                selection_reason = \"frequency_energy\"\n            \n            if selected:\n                tiles.append((tile_image, (x, y), breast_ratio, freq_energy, selection_reason))\n            else:\n                if freq_energy < min_freq_energy:\n                    rejected_freq_energy += 1\n                else:\n                    rejected_breast_ratio += 1\n    \n    total_attempted = len(y_positions) * len(x_positions)\n    print(f\"  Tile rejection analysis:\")\n    print(f\"    - Total tile positions: {total_attempted}\")\n    print(f\"    - Rejected as background: {rejected_background} ({rejected_background/total_attempted*100:.1f}%)\")\n    print(f\"    - Rejected for low intensity: {rejected_intensity}\")\n    print(f\"    - Rejected for low breast ratio: {rejected_breast_ratio}\")\n    print(f\"    - Rejected for low frequency energy: {rejected_freq_energy}\")\n    print(f\"    - ACCEPTED: {len(tiles)} ({len(tiles)/total_attempted*100:.1f}%)\")\n    \n    return tiles\n\n\ndef analyze_tile_quality_aggressive(tiles):\n    \"\"\"\n    Enhanced tile quality analysis with background contamination detection\n    \"\"\"\n    if not tiles:\n        return {}\n    \n    breast_ratios = [t[2] for t in tiles]\n    freq_energies = [t[3] for t in tiles]\n    intensities = [np.mean(t[0]) for t in tiles]\n    selection_reasons = [t[4] for t in tiles]\n    \n    # Background contamination check\n    potentially_problematic = 0\n    for tile_img, coords, breast_ratio, freq_energy, reason in tiles:\n        if is_background_tile(tile_img):\n            potentially_problematic += 1\n    \n    # Separate by selection method\n    breast_tiles = [t for t in tiles if t[4] == \"breast_tissue\"]\n    freq_tiles = [t for t in tiles if t[4] == \"frequency_energy\"]\n    \n    analysis = {\n        'total_tiles': len(tiles),\n        'breast_method_tiles': len(breast_tiles),\n        'freq_method_tiles': len(freq_tiles),\n        'avg_breast_ratio': np.mean(breast_ratios),\n        'avg_freq_energy': np.mean(freq_energies),\n        'avg_intensity': np.mean(intensities),\n        'min_intensity': np.min(intensities),\n        'max_intensity': np.max(intensities),\n        'std_intensity': np.std(intensities),\n        'potentially_problematic': potentially_problematic,\n        'background_contamination_pct': potentially_problematic / len(tiles) * 100 if tiles else 0\n    }\n    \n    return analysis\n\n\ndef create_medical_transforms(input_size: int):\n    \"\"\"\n    Create BYOL transforms optimized for medical imaging - EXACT MATCH with train_byol_mammo.py\n    \"\"\"\n    import torchvision.transforms as T\n    \n    # Medical-appropriate transforms for View 1 (lighter augmentations)\n    view1_transform = T.Compose([\n        T.ToTensor(),\n        T.RandomHorizontalFlip(p=0.5),\n        T.RandomRotation(degrees=7, fill=0),  # Small rotations to preserve anatomy\n        T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),  # Mild brightness/contrast, no color\n        T.Resize(input_size, antialias=True),\n        T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Grayscale-appropriate normalization for replicated channels\n    ])\n    \n    # Medical-appropriate transforms for View 2 (slightly stronger augmentations)  \n    view2_transform = T.Compose([\n        T.ToTensor(),\n        T.RandomHorizontalFlip(p=0.5),\n        T.RandomRotation(degrees=7, fill=0),\n        T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0, hue=0),  # Slightly stronger\n        T.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05), fill=0),  # Small translations/scaling\n        T.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),  # Very mild blur to preserve details\n        T.Resize(input_size, antialias=True),\n        T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Grayscale-appropriate normalization for replicated channels\n    ])\n    \n    return BYOLTransform(\n        view_1_transform=view1_transform,\n        view_2_transform=view2_transform,\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images in split_images/training\n",
      "✅ Processing 10 sample images to demonstrate medical BYOL pipeline\n"
     ]
    }
   ],
   "source": [
    "# Get sample images from the dataset\n",
    "image_paths = list(DATA_DIR.glob(\"*.png\"))\n",
    "print(f\"Found {len(image_paths)} images in {DATA_DIR}\")\n",
    "\n",
    "if len(image_paths) == 0:\n",
    "    print(\"❌ No images found! Make sure the path is correct and contains .png files\")\n",
    "else:\n",
    "    # Select random sample\n",
    "    sample_paths = random.sample(image_paths, min(NUM_SAMPLES, len(image_paths)))\n",
    "    print(f\"✅ Processing {len(sample_paths)} sample images to demonstrate medical BYOL pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process each sample image with AGGRESSIVE background rejection\nresults = []\n\nif 'sample_paths' in locals() and len(sample_paths) > 0:\n    for i, img_path in enumerate(tqdm(sample_paths, desc=\"Processing with AGGRESSIVE background rejection\")):\n        print(f\"\\nProcessing image {i+1}: {img_path.name}\")\n        \n        # Load image\n        with Image.open(img_path) as img:\n            img_array = np.array(img)\n        \n        print(f\"  Image shape: {img_array.shape}\")\n        print(f\"  Image intensity range: [{np.min(img_array)}, {np.max(img_array)}]\")\n        \n        # Enhanced breast tissue segmentation\n        breast_mask = segment_breast_tissue(img_array)\n        breast_area = np.sum(breast_mask)\n        total_area = breast_mask.shape[0] * breast_mask.shape[1]\n        breast_percentage = (breast_area / total_area) * 100\n        \n        print(f\"  Breast tissue: {breast_percentage:.1f}% of image\")\n        \n        # Extract tiles with AGGRESSIVE background rejection\n        tiles = extract_breast_tiles_with_freq_energy(\n            img_array, breast_mask, TILE_SIZE, TILE_STRIDE, \n            MIN_BREAST_RATIO, MIN_FREQ_ENERGY, MIN_BREAST_FOR_FREQ\n        )\n        \n        # Analyze tile quality with background contamination check\n        tile_analysis = analyze_tile_quality_aggressive(tiles)\n        \n        # Separate tiles by selection criteria\n        breast_tiles = [t for t in tiles if t[4] == \"breast_tissue\"]\n        freq_tiles = [t for t in tiles if t[4] == \"frequency_energy\"]\n        \n        print(f\"  FINAL RESULTS:\")\n        print(f\"    - Total selected tiles: {len(tiles)}\")\n        print(f\"    - Breast tissue method: {len(breast_tiles)}\")\n        print(f\"    - Frequency energy method: {len(freq_tiles)}\")\n        print(f\"    - Average intensity: {tile_analysis.get('avg_intensity', 0):.1f}\")\n        print(f\"    - Minimum intensity: {tile_analysis.get('min_intensity', 0):.1f}\")\n        print(f\"    - Background contamination: {tile_analysis.get('background_contamination_pct', 0):.1f}%\")\n        \n        if tile_analysis.get('background_contamination_pct', 0) == 0:\n            print(f\"    ✅ NO background contamination detected!\")\n        elif tile_analysis.get('background_contamination_pct', 0) < 5:\n            print(f\"    ⚠️  Minimal background contamination\")\n        else:\n            print(f\"    🔴 Significant background contamination - need even stricter filtering\")\n        \n        results.append({\n            'path': img_path,\n            'image': img_array,\n            'mask': breast_mask,\n            'tiles': tiles,\n            'breast_tiles': breast_tiles,\n            'freq_tiles': freq_tiles,\n            'breast_percentage': breast_percentage,\n            'tile_analysis': tile_analysis\n        })\n\n    print(f\"\\n✅ Completed processing {len(results)} images with AGGRESSIVE background rejection\")\n    print(f\"   🛡️  Multiple rejection criteria: background detection, intensity thresholds, tissue ratios\")\n    print(f\"   🎯  Thresholds: MIN_BREAST_RATIO={MIN_BREAST_RATIO:.0%}, MIN_FREQ_ENERGY={MIN_FREQ_ENERGY:.3f}\")\n    print(f\"   🔍  Intensity gates: ≥{MIN_TILE_INTENSITY} (all), ≥{MIN_TILE_INTENSITY+10} (frequency)\")\n    print(f\"   📊  Non-zero pixel requirement: ≥{MIN_NON_ZERO_PIXELS:.0%}\")\nelse:\n    print(\"❌ No sample images to process\")"
  },
  {
   "cell_type": "code",
   "source": "def demonstrate_background_rejection_effectiveness(results):\n    \"\"\"\n    Show before/after comparison - what tiles would have been selected with old vs new criteria\n    \"\"\"\n    if not results:\n        print(\"❌ No results to analyze\")\n        return\n    \n    print(\"🔍 BACKGROUND REJECTION EFFECTIVENESS DEMONSTRATION\")\n    print(\"=\" * 60)\n    \n    # Sample one result with sufficient data\n    demo_result = None\n    for result in results:\n        if len(result['tiles']) > 0:\n            demo_result = result\n            break\n    \n    if not demo_result:\n        print(\"❌ No tiles found for demonstration\")\n        return\n    \n    img_array = demo_result['image']\n    breast_mask = demo_result['mask']\n    \n    # Generate tiles with OLD (permissive) criteria for comparison\n    old_tiles = []\n    rejected_old_tiles = []  # These would have been selected before but are rejected now\n    \n    height, width = img_array.shape[:2]\n    positions = []\n    for y in range(0, max(1, height - TILE_SIZE + 1), TILE_STRIDE):\n        for x in range(0, max(1, width - TILE_SIZE + 1), TILE_STRIDE):\n            positions.append((x, y))\n    \n    # Sample random positions for comparison\n    sample_positions = random.sample(positions, min(20, len(positions)))\n    \n    for x, y in sample_positions:\n        tile_image = img_array[y:y+TILE_SIZE, x:x+TILE_SIZE]\n        tile_mask = breast_mask[y:y+TILE_SIZE, x:x+TILE_SIZE]\n        breast_ratio = np.sum(tile_mask) / (TILE_SIZE * TILE_SIZE)\n        mean_intensity = np.mean(tile_image)\n        \n        # OLD criteria (what would have been selected before)\n        old_min_breast = 0.05  # Much more permissive\n        old_min_intensity = 15  # Much lower\n        \n        would_select_old = (breast_ratio >= old_min_breast and mean_intensity >= old_min_intensity)\n        \n        # NEW criteria (current aggressive filtering)\n        is_background = is_background_tile(tile_image)\n        passes_new_criteria = (not is_background and \n                             mean_intensity >= MIN_TILE_INTENSITY and \n                             breast_ratio >= MIN_BREAST_RATIO)\n        \n        if would_select_old and passes_new_criteria:\n            old_tiles.append((tile_image, mean_intensity, breast_ratio, \"good_tile\"))\n        elif would_select_old and not passes_new_criteria:\n            rejected_old_tiles.append((tile_image, mean_intensity, breast_ratio, \"rejected_now\"))\n    \n    print(f\"📊 COMPARISON RESULTS:\")\n    print(f\"   • Tiles that would pass OLD criteria: {len(old_tiles) + len(rejected_old_tiles)}\")\n    print(f\"   • Tiles that pass NEW criteria: {len(old_tiles)}\")\n    print(f\"   • Background tiles REJECTED by new criteria: {len(rejected_old_tiles)}\")\n    if len(old_tiles) + len(rejected_old_tiles) > 0:\n        print(f\"   • Background rejection rate: {len(rejected_old_tiles)/(len(old_tiles) + len(rejected_old_tiles))*100:.1f}%\")\n    \n    # Visual comparison with improved formatting\n    if len(rejected_old_tiles) > 0:\n        n_show = min(6, len(rejected_old_tiles))\n        fig, axes = plt.subplots(2, 6, figsize=(20, 8))\n        fig.suptitle(\"Background Rejection Effectiveness: Accepted vs Rejected Tiles\", fontsize=16, y=0.98)\n        \n        # Top row: Good tiles (pass both old and new criteria)\n        if len(old_tiles) > 0:\n            for i in range(min(6, len(old_tiles))):\n                tile_img, intensity, breast_ratio, status = old_tiles[i]\n                axes[0, i].imshow(tile_img, cmap='gray')\n                \n                # Multi-line title to prevent overlap\n                title_lines = [\n                    \"✅ ACCEPTED\",\n                    f\"Int: {intensity:.0f}\",\n                    f\"Breast: {breast_ratio:.1%}\"\n                ]\n                axes[0, i].set_title('\\n'.join(title_lines), fontsize=9, pad=8, color='green')\n                axes[0, i].axis('off')\n        \n        # Bottom row: Rejected tiles (would pass old but fail new criteria)  \n        for i in range(min(6, len(rejected_old_tiles))):\n            tile_img, intensity, breast_ratio, status = rejected_old_tiles[i]\n            axes[1, i].imshow(tile_img, cmap='gray')\n            \n            # Multi-line title to prevent overlap\n            title_lines = [\n                \"🚫 REJECTED\", \n                f\"Int: {intensity:.0f}\",\n                f\"Breast: {breast_ratio:.1%}\"\n            ]\n            axes[1, i].set_title('\\n'.join(title_lines), fontsize=9, pad=8, color='red')\n            axes[1, i].axis('off')\n        \n        # Fill remaining slots\n        for i in range(len(old_tiles), 6):\n            axes[0, i].axis('off')\n        for i in range(len(rejected_old_tiles), 6):\n            axes[1, i].axis('off')\n        \n        plt.tight_layout()\n        plt.subplots_adjust(top=0.92)  # Make room for main title\n        plt.show()\n        \n        print(f\"\\n✅ SUCCESS: New criteria successfully reject background tiles!\")\n        print(f\"   • Rejected tiles show clear background/empty space contamination\")\n        print(f\"   • Accepted tiles have meaningful tissue content\")\n    else:\n        print(f\"\\n🎯 PERFECT: No problematic tiles found - all tiles pass quality criteria!\")\n\n# Run background rejection demonstration\nif results and len(results) > 0:\n    demonstrate_background_rejection_effectiveness(results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def display_byol_augmentations(results, num_augmentations=6):\n    \"\"\"\n    Display the medical-optimized BYOL augmentations on sample tiles\n    \"\"\"\n    if not results:\n        print(\"❌ No results to display\")\n        return\n    \n    # Create the medical transforms - EXACT match with train_byol_mammo.py\n    transform = create_medical_transforms(TILE_SIZE)\n    \n    # Select a result with tiles\n    result = None\n    for r in results:\n        if len(r['tiles']) > 3:\n            result = r\n            break\n    \n    if result is None:\n        print(\"❌ No results with sufficient tiles found\")\n        return\n    \n    # Select a few interesting tiles (mix of breast tissue and frequency energy tiles)\n    sample_tiles = []\n    if len(result['breast_tiles']) > 0:\n        sample_tiles.extend(random.sample(result['breast_tiles'], min(2, len(result['breast_tiles']))))\n    if len(result['freq_tiles']) > 0:\n        sample_tiles.extend(random.sample(result['freq_tiles'], min(2, len(result['freq_tiles']))))\n    \n    if not sample_tiles:\n        sample_tiles = random.sample(result['tiles'], min(3, len(result['tiles'])))\n    \n    print(\"🎯 MEDICAL-OPTIMIZED BYOL AUGMENTATIONS (EXACT MATCH WITH TRAINING)\")\n    print(\"=\" * 70)\n    print(\"View 1: Lighter augmentations - RandomHorizontalFlip(0.5), RandomRotation(±7°), ColorJitter(brightness=0.1, contrast=0.1)\")\n    print(\"View 2: Stronger augmentations - + RandomAffine(translate=±5%, scale=0.95-1.05), GaussianBlur(σ=0.1-0.5)\")\n    print(\"Note: Medical-safe - No strong color distortion, solarization, or anatomy-disrupting transforms\")\n    \n    for i, tile_data in enumerate(sample_tiles[:3]):\n        # Handle tile data with 5 elements: (tile_img, coords, breast_ratio, freq_energy, selection_reason)\n        tile_img = tile_data[0]\n        coords = tile_data[1] \n        breast_ratio = tile_data[2]\n        freq_energy = tile_data[3]\n        selection_reason = tile_data[4] if len(tile_data) > 4 else \"unknown\"\n        \n        # Convert tile to PIL Image and prepare for transforms\n        if tile_img.max() <= 1.0:\n            tile_img = (tile_img * 255).astype(np.uint8)\n        \n        # Convert to grayscale then RGB (same as in training pipeline)\n        pil_tile = Image.fromarray(tile_img.astype(np.uint8))\n        if pil_tile.mode != 'L':\n            pil_tile = pil_tile.convert('L')\n        pil_tile = pil_tile.convert('RGB')  # Replicate grayscale channel\n        \n        # Generate multiple augmentations\n        fig, axes = plt.subplots(2, 4, figsize=(16, 10))\n        \n        # Clear multi-line title to avoid overlap\n        title_lines = [\n            f\"BYOL Medical Augmentations - Tile {i+1}\",\n            f\"Method: {selection_reason.replace('_', ' ').title()}\",\n            f\"Breast: {breast_ratio:.1%} | Freq: {freq_energy:.3f}\"\n        ]\n        fig.suptitle('\\n'.join(title_lines), fontsize=14, y=0.98)\n        \n        # Original tile\n        axes[0, 0].imshow(tile_img, cmap='gray')\n        axes[0, 0].set_title(\"Original Tile\", fontsize=10, pad=8)\n        axes[0, 0].axis('off')\n        \n        # Show multiple augmented versions\n        for j in range(1, 8):\n            row = j // 4\n            col = j % 4\n            \n            # Apply BYOL transforms\n            views = transform(pil_tile)\n            view1, view2 = views\n            \n            # Convert back to display format\n            if j <= 3:\n                # Show View 1 transforms (lighter)\n                display_tensor = view1\n                title = f\"View 1 Aug #{j}\"\n            else:\n                # Show View 2 transforms (stronger)\n                display_tensor = view2\n                title = f\"View 2 Aug #{j-3}\"\n            \n            # Denormalize for display\n            display_img = display_tensor.clone()\n            display_img = display_img * 0.5 + 0.5  # Reverse normalization\n            display_img = torch.clamp(display_img, 0, 1)\n            \n            # Convert to numpy and show\n            display_np = display_img.permute(1, 2, 0).numpy()\n            axes[row, col].imshow(display_np)\n            axes[row, col].set_title(title, fontsize=10, pad=8)\n            axes[row, col].axis('off')\n        \n        plt.tight_layout()\n        plt.subplots_adjust(top=0.90)  # Make room for multi-line title\n        plt.show()\n        \n        print(f\"\\nTile {i+1} Details:\")\n        print(f\"  • Selection method: {selection_reason.replace('_', ' ')}\")\n        print(f\"  • Breast tissue ratio: {breast_ratio:.1%}\")\n        print(f\"  • Frequency energy: {freq_energy:.3f}\")\n        print(f\"  • Position: ({coords[0]}, {coords[1]})\")\n\n# Display BYOL augmentations with exact training pipeline match\nif results:\n    display_byol_augmentations(results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive summary of the medical-optimized pipeline - EXACT MATCH with training pipeline\nif results:\n    total_tiles = sum(len(result['tiles']) for result in results)\n    total_breast_tiles = sum(len(result['breast_tiles']) for result in results)\n    total_freq_tiles = sum(len(result['freq_tiles']) for result in results)\n    avg_tiles_per_image = total_tiles / len(results) if results else 0\n    avg_breast_percentage = np.mean([result['breast_percentage'] for result in results])\n    \n    print(\"🏥 === MEDICAL-OPTIMIZED BYOL PIPELINE SUMMARY ===\")\n    print(\"=\" * 60)\n    print(f\"📊 Dataset Statistics:\")\n    print(f\"   • Total images processed: {len(results)}\")\n    print(f\"   • Total tiles generated: {total_tiles:,}\")\n    print(f\"   • Average tiles per image: {avg_tiles_per_image:.1f}\")\n    print(f\"   • Average breast tissue percentage: {avg_breast_percentage:.1f}%\")\n    \n    print(f\"\\n🎯 Tile Selection Strategy (AGGRESSIVE Background Rejection):\")\n    print(f\"   • Breast tissue tiles (≥{MIN_BREAST_RATIO:.1%} tissue): {total_breast_tiles:,} ({total_breast_tiles/total_tiles*100:.1f}%)\")\n    print(f\"   • Frequency energy tiles (≥{MIN_FREQ_ENERGY:.3f} energy): {total_freq_tiles:,} ({total_freq_tiles/total_tiles*100:.1f}%)\")\n    print(f\"   • Tile size: {TILE_SIZE}×{TILE_SIZE} pixels\")\n    print(f\"   • Tile stride: {TILE_STRIDE} pixels ({TILE_STRIDE/TILE_SIZE*100:.0f}% overlap)\")\n    \n    print(f\"\\n🔍 AGGRESSIVE Background Rejection Parameters:\")\n    print(f\"   🛡️  MIN_BREAST_RATIO: {MIN_BREAST_RATIO:.1%} (increased from 0.3)\")\n    print(f\"   🛡️  MIN_FREQ_ENERGY: {MIN_FREQ_ENERGY:.3f} (much higher threshold)\")\n    print(f\"   🛡️  MIN_BREAST_FOR_FREQ: {MIN_BREAST_FOR_FREQ:.1%} (stricter for frequency tiles)\")\n    print(f\"   🛡️  MIN_TILE_INTENSITY: {MIN_TILE_INTENSITY} (reject dark background)\")\n    print(f\"   🛡️  MIN_NON_ZERO_PIXELS: {MIN_NON_ZERO_PIXELS:.1%} (reject empty space)\")\n    \n    print(f\"\\n🔬 Medical Improvements vs Original:\")\n    print(f\"   ✅ Lowered breast ratio threshold: 0.3 → {MIN_BREAST_RATIO} (captures peripheral regions)\")\n    print(f\"   ✅ Added frequency energy detection: micro-calcification sensitivity\")\n    print(f\"   ✅ Gentle segmentation: preserves medical details\")\n    print(f\"   ✅ Grayscale-appropriate preprocessing: L→RGB replication\")\n    print(f\"   ✅ AGGRESSIVE background rejection: NO empty space tiles\")\n    \n    print(f\"\\n🎛️ BYOL Augmentation Optimizations (EXACT MATCH with train_byol_mammo.py):\")\n    print(f\"   ✅ Medical-safe rotations: ±7° (preserves anatomy)\")\n    print(f\"   ✅ View 1: Mild brightness/contrast (0.1/0.1), horizontal flip\") \n    print(f\"   ✅ View 2: Stronger brightness/contrast (0.15/0.15) + affine + blur\")\n    print(f\"   ✅ RandomAffine: translate=±5%, scale=0.95-1.05\")\n    print(f\"   ✅ GaussianBlur: kernel=3, σ=0.1-0.5 (preserves calcification details)\")\n    print(f\"   ✅ No solarization/strong color jitter: medical data integrity\")\n    print(f\"   ✅ Normalization: mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5] (grayscale-appropriate)\")\n    \n    print(f\"\\n⚡ A100 Performance Optimizations (from train_byol_mammo.py):\")\n    print(f\"   ✅ Mixed precision training: autocast + GradScaler\")\n    print(f\"   ✅ Per-step momentum updates: better convergence\")\n    print(f\"   ✅ Optimized hyperparameters: LR=3e-4, WD=1e-4, BATCH_SIZE=8\")\n    print(f\"   ✅ Multi-label classification ready: [mass, calcification]\")\n    print(f\"   ✅ BYOL architecture: ResNet50 + projection heads\")\n    \n    # Distribution visualization with improved formatting\n    breast_ratios = []\n    freq_energies = []\n    for result in results:\n        for tile_data in result['tiles']:\n            # Handle 5-element tuple: (tile_img, coords, breast_ratio, freq_energy, selection_reason)\n            breast_ratio = tile_data[2]\n            freq_energy = tile_data[3]\n            breast_ratios.append(breast_ratio)\n            freq_energies.append(freq_energy)\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n    fig.suptitle('Medical-Optimized Tile Selection Quality Distributions', fontsize=16, y=0.98)\n    \n    # Breast ratio distribution\n    ax1.hist(breast_ratios, bins=20, alpha=0.7, edgecolor='black', color='green')\n    ax1.axvline(MIN_BREAST_RATIO, color='red', linestyle='--', linewidth=2, \n                label=f'AGGRESSIVE Threshold: {MIN_BREAST_RATIO:.1%}')\n    ax1.set_xlabel('Breast Tissue Ratio', fontsize=12)\n    ax1.set_ylabel('Number of Tiles', fontsize=12)\n    ax1.set_title('Breast Tissue Ratios\\n(Higher = More Tissue Content)', fontsize=12, pad=10)\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Frequency energy distribution\n    ax2.hist(freq_energies, bins=20, alpha=0.7, edgecolor='black', color='orange')\n    ax2.axvline(MIN_FREQ_ENERGY, color='red', linestyle='--', linewidth=2,\n                label=f'AGGRESSIVE Threshold: {MIN_FREQ_ENERGY:.3f}')\n    ax2.set_xlabel('Frequency Energy (LoG variance)', fontsize=12)\n    ax2.set_ylabel('Number of Tiles', fontsize=12) \n    ax2.set_title('Frequency Energy Distribution\\n(Higher = More Calcification-like Features)', fontsize=12, pad=10)\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.subplots_adjust(top=0.90)\n    plt.show()\n    \n    print(f\"\\n🚀 TRAINING READINESS:\")\n    print(f\"   • Configuration matches train_byol_mammo.py exactly\")\n    print(f\"   • AGGRESSIVE background rejection eliminates empty tiles\")\n    print(f\"   • Medical-optimized augmentations preserve anatomical details\")\n    print(f\"   • Ready for A100 training: sbatch submit_byol.sbatch\")\n    \n    # Final quality check\n    total_quality_issues = sum(result['tile_analysis'].get('potentially_problematic', 0) for result in results)\n    if total_quality_issues == 0:\n        print(f\"   ✅ PERFECT: Zero background contamination across all tiles!\")\n    else:\n        contamination_rate = total_quality_issues / total_tiles * 100\n        print(f\"   ⚠️  Background contamination: {contamination_rate:.2f}% ({total_quality_issues}/{total_tiles} tiles)\")\n    \nelse:\n    print(\"❌ No results to summarize - please check the data directory path\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def display_byol_augmentations(results, num_augmentations=6):\n    \"\"\"\n    Display the medical-optimized BYOL augmentations on sample tiles\n    \"\"\"\n    if not results:\n        print(\"❌ No results to display\")\n        return\n    \n    # Create the medical transforms\n    transform = create_medical_transforms(TILE_SIZE)\n    \n    # Select a result with tiles\n    result = None\n    for r in results:\n        if len(r['tiles']) > 3:\n            result = r\n            break\n    \n    if result is None:\n        print(\"❌ No results with sufficient tiles found\")\n        return\n    \n    # Select a few interesting tiles (mix of breast tissue and frequency energy tiles)\n    sample_tiles = []\n    if len(result['breast_tiles']) > 0:\n        sample_tiles.extend(random.sample(result['breast_tiles'], min(2, len(result['breast_tiles']))))\n    if len(result['freq_tiles']) > 0:\n        sample_tiles.extend(random.sample(result['freq_tiles'], min(2, len(result['freq_tiles']))))\n    \n    if not sample_tiles:\n        sample_tiles = random.sample(result['tiles'], min(3, len(result['tiles'])))\n    \n    for i, tile_data in enumerate(sample_tiles[:3]):\n        # Handle tile data with 5 elements: (tile_img, coords, breast_ratio, freq_energy, selection_reason)\n        tile_img = tile_data[0]\n        coords = tile_data[1] \n        breast_ratio = tile_data[2]\n        freq_energy = tile_data[3]\n        selection_reason = tile_data[4] if len(tile_data) > 4 else \"unknown\"\n        \n        # Convert tile to PIL Image and prepare for transforms\n        if tile_img.max() <= 1.0:\n            tile_img = (tile_img * 255).astype(np.uint8)\n        \n        # Convert to grayscale then RGB (same as in training pipeline)\n        pil_tile = Image.fromarray(tile_img.astype(np.uint8))\n        if pil_tile.mode != 'L':\n            pil_tile = pil_tile.convert('L')\n        pil_tile = pil_tile.convert('RGB')  # Replicate grayscale channel\n        \n        # Generate multiple augmentations\n        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n        fig.suptitle(f\"BYOL Medical Augmentations - Tile {i+1} (Breast: {breast_ratio:.1%}, Freq: {freq_energy:.3f}, Method: {selection_reason})\", fontsize=14)\n        \n        # Original tile\n        axes[0, 0].imshow(tile_img, cmap='gray')\n        axes[0, 0].set_title(\"Original Tile\")\n        axes[0, 0].axis('off')\n        \n        # Show multiple augmented versions\n        for j in range(1, 8):\n            row = j // 4\n            col = j % 4\n            \n            # Apply BYOL transforms\n            views = transform(pil_tile)\n            view1, view2 = views\n            \n            # Convert back to display format\n            if j <= 3:\n                # Show View 1 transforms (lighter)\n                display_tensor = view1\n                title = f\"View 1 Aug #{j}\"\n            else:\n                # Show View 2 transforms (stronger)\n                display_tensor = view2\n                title = f\"View 2 Aug #{j-3}\"\n            \n            # Denormalize for display\n            display_img = display_tensor.clone()\n            display_img = display_img * 0.5 + 0.5  # Reverse normalization\n            display_img = torch.clamp(display_img, 0, 1)\n            \n            # Convert to numpy and show\n            display_np = display_img.permute(1, 2, 0).numpy()\n            axes[row, col].imshow(display_np)\n            axes[row, col].set_title(title)\n            axes[row, col].axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n\n# Display BYOL augmentations\nif results:\n    print(\"🎯 Demonstrating Medical-Optimized BYOL Augmentations\")\n    print(\"View 1: Lighter augmentations (horizontal flip, ±7° rotation, mild brightness/contrast)\")\n    print(\"View 2: Stronger augmentations (+ translation, scaling, mild blur)\")\n    print(\"Note: No strong color jitter/solarization to preserve medical details\\n\")\n    \n    display_byol_augmentations(results)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Comprehensive summary of the medical-optimized pipeline\nif results:\n    total_tiles = sum(len(result['tiles']) for result in results)\n    total_breast_tiles = sum(len(result['breast_tiles']) for result in results)\n    total_freq_tiles = sum(len(result['freq_tiles']) for result in results)\n    avg_tiles_per_image = total_tiles / len(results) if results else 0\n    avg_breast_percentage = np.mean([result['breast_percentage'] for result in results])\n    \n    print(\"🏥 === MEDICAL-OPTIMIZED BYOL PIPELINE SUMMARY ===\")\n    print(f\"📊 Dataset Statistics:\")\n    print(f\"   • Total images processed: {len(results)}\")\n    print(f\"   • Total tiles generated: {total_tiles:,}\")\n    print(f\"   • Average tiles per image: {avg_tiles_per_image:.1f}\")\n    print(f\"   • Average breast tissue percentage: {avg_breast_percentage:.1f}%\")\n    \n    print(f\"\\n🎯 Tile Selection Strategy:\")\n    print(f\"   • Breast tissue tiles (≥{MIN_BREAST_RATIO:.1%} tissue): {total_breast_tiles:,} ({total_breast_tiles/total_tiles*100:.1f}%)\")\n    print(f\"   • Frequency energy tiles (≥{MIN_FREQ_ENERGY:.3f} energy): {total_freq_tiles:,} ({total_freq_tiles/total_tiles*100:.1f}%)\")\n    print(f\"   • Tile size: {TILE_SIZE}×{TILE_SIZE} pixels\")\n    print(f\"   • Tile stride: {TILE_STRIDE} pixels ({TILE_STRIDE/TILE_SIZE*100:.0f}% overlap)\")\n    \n    print(f\"\\n🔬 Medical Improvements vs Original:\")\n    print(f\"   ✅ Lowered breast ratio threshold: 0.3 → {MIN_BREAST_RATIO} (captures peripheral regions)\")\n    print(f\"   ✅ Added frequency energy detection: micro-calcification sensitivity\")\n    print(f\"   ✅ Gentle segmentation: preserves medical details\")\n    print(f\"   ✅ Grayscale-appropriate preprocessing: L→RGB replication\")\n    \n    print(f\"\\n🎛️ BYOL Augmentation Optimizations:\")\n    print(f\"   ✅ Medical-safe rotations: ±7° (preserves anatomy)\")\n    print(f\"   ✅ Mild brightness/contrast: no color distortion\") \n    print(f\"   ✅ Light blur: preserves calcification details\")\n    print(f\"   ✅ No solarization/strong color jitter: medical data integrity\")\n    \n    print(f\"\\n⚡ A100 Performance Optimizations:\")\n    print(f\"   ✅ Mixed precision training: autocast + GradScaler\")\n    print(f\"   ✅ Per-step momentum updates: better convergence\")\n    print(f\"   ✅ Optimized hyperparameters: LR=3e-4, WD=1e-4 (batch=8)\")\n    print(f\"   ✅ Multi-label classification ready: [mass, calcification]\")\n    \n    # Distribution visualization - handle 5-element tile data\n    breast_ratios = []\n    freq_energies = []\n    for result in results:\n        for tile_data in result['tiles']:\n            # Handle 5-element tuple: (tile_img, coords, breast_ratio, freq_energy, selection_reason)\n            breast_ratio = tile_data[2]\n            freq_energy = tile_data[3]\n            breast_ratios.append(breast_ratio)\n            freq_energies.append(freq_energy)\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n    \n    # Breast ratio distribution\n    ax1.hist(breast_ratios, bins=20, alpha=0.7, edgecolor='black', color='green')\n    ax1.axvline(MIN_BREAST_RATIO, color='red', linestyle='--', label=f'Threshold: {MIN_BREAST_RATIO:.1%}')\n    ax1.set_xlabel('Breast Tissue Ratio')\n    ax1.set_ylabel('Number of Tiles')\n    ax1.set_title('Distribution of Breast Tissue Ratios')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Frequency energy distribution\n    ax2.hist(freq_energies, bins=20, alpha=0.7, edgecolor='black', color='orange')\n    ax2.axvline(MIN_FREQ_ENERGY, color='red', linestyle='--', label=f'Threshold: {MIN_FREQ_ENERGY:.3f}')\n    ax2.set_xlabel('Frequency Energy (LoG variance)')\n    ax2.set_ylabel('Number of Tiles')\n    ax2.set_title('Distribution of Frequency Energy (Calcification Detection)')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\n🚀 Ready for A100 training with: sbatch submit_byol.sbatch\")\n    \nelse:\n    print(\"❌ No results to summarize - please check the data directory path\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byol_vindr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}