# BYOL Mammogram Training

Self-supervised BYOL (Bootstrap Your Own Latent) pre-training on mammogram images with enhanced breast tissue segmentation and optimized augmentations for effective self-supervised learning.

## ğŸ”¬ Enhanced Features

- **Advanced Breast Segmentation**: Aggressive background rejection with multi-level filtering
- **Enhanced BYOL Augmentations**: Stronger augmentations for effective self-supervised learning
- **Larger High-Quality Tiles**: 512Ã—512 tiles for better context and 4x fewer tiles
- **A100 GPU Optimized**: Mixed precision training with maximum performance settings
- **Medical-Safe Augmentations**: Strong enough for BYOL while preserving diagnostic details
- **Frequency-Based Selection**: Micro-calcification detection for comprehensive tissue analysis
- **Classification Ready**: Multi-label classification head for [mass, calcification] detection
- **WandB Integration**: Real-time experiment tracking and visualization
- **Intelligent Caching**: Tile extraction cached to avoid ~57-minute re-processing

## ğŸ“‹ Requirements

```bash
pip install -r requirements.txt
```

## ğŸš€ Quick Start

### 1. Prepare Dataset

```bash
python prepare_dataset.py \
    --csv_path /path/to/breast-level_annotations.csv \
    --images_root /path/to/images_png \
    --output_dir ./split_images
```

### 2. Start Training

```bash
python train_byol_mammo.py
```

### 3. Optional: Enable WandB Tracking

```bash
wandb login
python train_byol_mammo.py
```

## ğŸ“Š Expected Results

- **Dataset**: ~11,000 high-quality breast tissue tiles from 16,000 mammograms
- **Efficiency**: 75% reduction in tiles while improving quality (512Ã—512 vs 256Ã—256)
- **Model**: ResNet50 backbone with 28M+ parameters + classification head
- **Training Speed**: 4-5 hours on A100-80GB (vs 8+ hours previously)
- **Quality**: Zero background contamination with aggressive filtering
- **Output**: Multi-label classification-ready model for [mass, calcification] detection

## ğŸ—ï¸ Enhanced Architecture

```
Input Mammogram â†’ Enhanced Segmentation â†’ Frequency Analysis â†’ 512Ã—512 Tile Extraction
                                                                      â†“
                                                            Enhanced BYOL Training
                                                                      â†“
ImageNet ResNet50 â†’ Projection Head (2048â†’4096â†’256) â†’ Prediction Head â†’ BYOL Loss
       â†“                                                              
Classification Head (2048â†’2048â†’2) [mass, calcification]
```

### Key Improvements:
- **Larger Tiles**: 512Ã—512 for better context (4x larger)
- **Enhanced Augmentations**: View1 (Â±15Â° rotation, 0.3 brightness/contrast) + View2 (Â±25Â° rotation, 0.4 brightness/contrast, perspective, blur)
- **Dual Selection**: Breast tissue ratio + frequency energy for micro-calcifications
- **A100 Optimized**: Mixed precision, large batch (32), scaled LR (2e-3)

## ğŸ“ Project Structure

```
â”œâ”€â”€ train_byol_mammo.py       # Main training script
â”œâ”€â”€ prepare_dataset.py        # Dataset preparation CLI
â”œâ”€â”€ breast_segmentation_tiling.ipynb  # Segmentation demo
â”œâ”€â”€ requirements.txt          # Dependencies
â””â”€â”€ README.md                # This file
```

## ğŸ”§ Enhanced Configuration

Key parameters in `train_byol_mammo.py`:

### Tile Processing:
- `TILE_SIZE = 512`: Larger tiles for better context (increased from 256)
- `TILE_STRIDE = 256`: 50% overlap for comprehensive coverage
- `MIN_BREAST_RATIO = 0.15`: Minimum breast tissue per tile (more permissive)
- `MIN_FREQ_ENERGY = 0.03`: Micro-calcification detection threshold
- `MIN_TILE_INTENSITY = 40`: Background rejection threshold
- `MIN_NON_ZERO_PIXELS = 0.7`: Empty space rejection (70% meaningful pixels)

### Training Optimization:
- `BATCH_SIZE = 32`: A100-optimized batch size
- `NUM_WORKERS = 16`: Maximum CPU utilization  
- `LR = 2e-3`: Scaled learning rate with 10-epoch warmup
- `EPOCHS = 100`: Full training cycle
- `MOMENTUM_BASE = 0.996`: Per-step momentum updates

### BYOL Augmentations:
- **View 1**: Â±15Â° rotation, 0.3 brightness/contrast, scale 0.85-1.15
- **View 2**: Â±25Â° rotation, 0.4 brightness/contrast, perspective, blur, grayscale

## ğŸ¯ Usage for Classification

After BYOL pre-training, use the model for classification:

```python
# Load pre-trained BYOL model
model = MammogramBYOL(backbone, INPUT_DIM, HIDDEN_DIM, PROJ_DIM)
model.load_state_dict(torch.load('mammogram_byol_best.pth')['model_state_dict'])

# Extract features or classify
features = model.get_features(image_tensor)
predictions = model.classify(image_tensor)
```

## ğŸ“ˆ Enhanced Monitoring

Training metrics tracked:
- **BYOL Loss**: Negative cosine similarity (should converge more slowly with stronger augmentations)
- **Learning Rate**: Warmup + cosine annealing schedule
- **Breast Tissue Ratio**: Average per batch for quality monitoring
- **Momentum Schedule**: Per-step updates for optimal BYOL training
- **GPU Utilization**: A100 memory and compute efficiency
- **Training Speed**: Batches per second and time remaining
- **Model Checkpoints**: Best, periodic (every 10 epochs), and final models

### Expected Training Dynamics:
- **Early epochs**: Higher loss variability (good - indicates strong augmentations)
- **Mid training**: Gradual convergence without plateau
- **Final epochs**: Stable convergence around loss -0.95 to -0.99

## ğŸ–¥ï¸ Research Computing Deployment

1. **Clone repository** on your HPC system
2. **Install dependencies** with `pip install -r requirements.txt`
3. **Prepare dataset** with your specific paths using `prepare_dataset.py`
4. **Configure GPU**: Optimized for A100 GPUs (adjust batch size for smaller GPUs)
5. **Run training**: `python train_byol_mammo.py` or submit via SLURM

### Performance Expectations:
- **A100-80GB**: 4-5 hours for 100 epochs (optimal configuration)
- **A100-40GB**: 5-6 hours for 100 epochs  
- **V100**: 8-10 hours (reduce batch size to 16)
- **First run**: Additional ~57 minutes for tile extraction (then cached)

### Key Benefits:
- **Faster Training**: 4x fewer tiles due to larger tile size
- **Better Quality**: Aggressive background rejection ensures no empty tiles
- **Medical Safety**: Strong augmentations that preserve diagnostic information
- **Production Ready**: Multi-label classification head included for immediate deployment

Designed for scalable deployment on HPC systems with comprehensive GPU optimization.