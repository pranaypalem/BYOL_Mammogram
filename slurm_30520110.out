ğŸ“Š Estimated GPU Memory Usage: 6.9 GB
ğŸ’¡ Tip: GPU underutilized. Consider increasing batch size to 162 for A100-40GB

ğŸ”¬ Mammogram BYOL Training with AGGRESSIVE Background Rejection
============================================================
Device: cuda
Tile size: 512x512 (increased for fewer, higher quality tiles)
Tile stride: 256 pixels (50% overlap)

ğŸ” AGGRESSIVE Background Rejection Parameters:
  ğŸ›¡ï¸  MIN_BREAST_RATIO: 15.0% (increased from 0.3)
  ğŸ›¡ï¸  MIN_FREQ_ENERGY: 0.030 (much higher threshold)
  ğŸ›¡ï¸  MIN_BREAST_FOR_FREQ: 12.0% (stricter for frequency tiles)
  ğŸ›¡ï¸  MIN_TILE_INTENSITY: 40 (reject dark background)
  ğŸ›¡ï¸  MIN_NON_ZERO_PIXELS: 70.0% (reject empty space)

ğŸ›ï¸ Enhanced BYOL Augmentations for Effective Self-Supervised Learning:
  âœ… View 1: Moderate (brightness/contrast 0.3/0.3, Â±15Â° rotation, scale 0.85-1.15)
  âœ… View 2: Strong (brightness/contrast 0.4/0.4, Â±25Â° rotation, perspective, blur)
  âœ… Added: Vertical flips, random perspective, random grayscale for diversity
  âœ… Balanced: Strong enough for BYOL while preserving medical details

Multi-level filtering eliminates ALL empty space tiles

[Dataset] Cache miss: Extracting tiles from 16000 mammogram images...
[Dataset] This will take ~57 minutes but will be cached for future runs...

[Dataset] AGGRESSIVE Background Rejection Results:
  â€¢ Generated 162,696 tiles from 240,000 possible (67.8% efficiency)
  â€¢ Breast tissue method tiles: 162,696
  â€¢ Frequency energy method tiles: 0
  â€¢ Average breast tissue per tile: 91.1%
  â€¢ Average frequency energy per tile: 0.0936
  â€¢ Background contamination check: SKIPPED (pre-filtered during extraction)
  âœ… All tiles passed AGGRESSIVE background rejection during extraction
  âœ… Quality assured: Multi-level filtering eliminated empty space tiles
[Dataset] ğŸ’¾ Saving tiles to cache: tile_cache_55920292a499.pkl
  âœ… Cache saved! Future runs will load instantly.
ğŸ“Š Dataset: 162,696 breast tissue tiles â†’ 5,084 batches
âœ… Using ImageNet-pretrained ResNet50 backbone for better medical domain transfer
ğŸš€ Enabling PyTorch 2.0 compile optimization for A100...
   âœ… Model compiled for maximum A100 performance
ğŸ§  Model: ResNet50 backbone with 68,012,928 parameters
ğŸ¯ Ready for downstream tasks with 2048D backbone features

âš¡ A100 GPU MAXIMUM PERFORMANCE OPTIMIZATIONS:
  ğŸš€ Large batch training: BATCH_SIZE=32 (4x increase)
  ğŸš€ Scaled learning rate: LR=0.002 with 10-epoch warmup
  ğŸš€ Mixed precision training: autocast + GradScaler
  ğŸš€ PyTorch 2.0 compile: max-autotune mode (if available)
  ğŸš€ Enhanced DataLoader: 16 workers, prefetch_factor=4
  ğŸš€ Per-step momentum updates: optimal BYOL convergence
  ğŸš€ Sequential LR scheduler: warmup â†’ cosine annealing
  ğŸš€ Gradient clipping: max_norm=1.0 for stability
  ğŸ’¾ Memory optimized: pin_memory + non_blocking transfers

Epoch   1/100 â”‚ Loss: -0.9613 â”‚ Breast: 91.1% â”‚ 25.9min
Epoch   2/100 â”‚ Loss: -0.9766 â”‚ Breast: 91.1% â”‚ 46.4min
Epoch   3/100 â”‚ Loss: -0.9748 â”‚ Breast: 91.1% â”‚ 69.9min
Epoch   4/100 â”‚ Loss: -0.9758 â”‚ Breast: 91.1% â”‚ 89.4min
Epoch   5/100 â”‚ Loss: -0.9765 â”‚ Breast: 91.1% â”‚ 109.3min
Epoch   6/100 â”‚ Loss: -0.9761 â”‚ Breast: 91.1% â”‚ 128.8min
Epoch   7/100 â”‚ Loss: -0.9767 â”‚ Breast: 91.1% â”‚ 148.5min
Epoch   8/100 â”‚ Loss: -0.9763 â”‚ Breast: 91.1% â”‚ 168.3min
Epoch   9/100 â”‚ Loss: -0.9758 â”‚ Breast: 91.1% â”‚ 189.4min
Epoch  10/100 â”‚ Loss: -0.9778 â”‚ Breast: 91.1% â”‚ 209.0min
Epoch  11/100 â”‚ Loss: -0.9760 â”‚ Breast: 91.1% â”‚ 228.8min
Epoch  12/100 â”‚ Loss: -0.9773 â”‚ Breast: 91.1% â”‚ 248.5min
Epoch  13/100 â”‚ Loss: -0.9795 â”‚ Breast: 91.1% â”‚ 269.5min
Epoch  14/100 â”‚ Loss: -0.9791 â”‚ Breast: 91.1% â”‚ 291.6min
Epoch  15/100 â”‚ Loss: -0.9808 â”‚ Breast: 91.1% â”‚ 311.9min
Epoch  16/100 â”‚ Loss: -0.9834 â”‚ Breast: 91.1% â”‚ 331.8min
Epoch  17/100 â”‚ Loss: -0.9835 â”‚ Breast: 91.1% â”‚ 351.7min
Epoch  18/100 â”‚ Loss: -0.9843 â”‚ Breast: 91.1% â”‚ 372.2min
Epoch  19/100 â”‚ Loss: -0.9852 â”‚ Breast: 91.1% â”‚ 392.1min
Epoch  20/100 â”‚ Loss: -0.9843 â”‚ Breast: 91.1% â”‚ 412.0min
Epoch  21/100 â”‚ Loss: -0.9859 â”‚ Breast: 91.1% â”‚ 432.0min
Epoch  22/100 â”‚ Loss: -0.9858 â”‚ Breast: 91.1% â”‚ 452.1min
Epoch  23/100 â”‚ Loss: -0.9875 â”‚ Breast: 91.1% â”‚ 472.3min
Epoch  24/100 â”‚ Loss: -0.9872 â”‚ Breast: 91.1% â”‚ 492.3min
Epoch  25/100 â”‚ Loss: -0.9882 â”‚ Breast: 91.1% â”‚ 512.3min
Epoch  26/100 â”‚ Loss: -0.9880 â”‚ Breast: 91.1% â”‚ 532.6min
Epoch  27/100 â”‚ Loss: -0.9882 â”‚ Breast: 91.1% â”‚ 552.7min
Epoch  28/100 â”‚ Loss: -0.9893 â”‚ Breast: 91.1% â”‚ 572.5min
Epoch  29/100 â”‚ Loss: -0.9892 â”‚ Breast: 91.1% â”‚ 592.2min
Epoch  30/100 â”‚ Loss: -0.9899 â”‚ Breast: 91.1% â”‚ 611.9min
Epoch  31/100 â”‚ Loss: -0.9901 â”‚ Breast: 91.1% â”‚ 631.6min
Epoch  32/100 â”‚ Loss: -0.9909 â”‚ Breast: 91.1% â”‚ 651.6min
Epoch  33/100 â”‚ Loss: -0.9901 â”‚ Breast: 91.1% â”‚ 671.4min
Epoch  34/100 â”‚ Loss: -0.9909 â”‚ Breast: 91.1% â”‚ 690.9min
Epoch  35/100 â”‚ Loss: -0.9908 â”‚ Breast: 91.1% â”‚ 710.4min
Epoch  36/100 â”‚ Loss: -0.9903 â”‚ Breast: 91.1% â”‚ 729.9min
Epoch  37/100 â”‚ Loss: -0.9911 â”‚ Breast: 91.1% â”‚ 749.6min
Epoch  38/100 â”‚ Loss: -0.9913 â”‚ Breast: 91.1% â”‚ 769.3min
Epoch  39/100 â”‚ Loss: -0.9915 â”‚ Breast: 91.1% â”‚ 788.8min
Epoch  40/100 â”‚ Loss: -0.9912 â”‚ Breast: 91.1% â”‚ 808.6min
Epoch  41/100 â”‚ Loss: -0.9909 â”‚ Breast: 91.1% â”‚ 827.9min
Epoch  42/100 â”‚ Loss: -0.9915 â”‚ Breast: 91.1% â”‚ 847.1min
Epoch  43/100 â”‚ Loss: -0.9908 â”‚ Breast: 91.1% â”‚ 866.8min
Epoch  44/100 â”‚ Loss: -0.9915 â”‚ Breast: 91.1% â”‚ 886.0min
Epoch  45/100 â”‚ Loss: -0.9909 â”‚ Breast: 91.1% â”‚ 905.6min
Epoch  46/100 â”‚ Loss: -0.9917 â”‚ Breast: 91.1% â”‚ 924.9min
Epoch  47/100 â”‚ Loss: -0.9919 â”‚ Breast: 91.1% â”‚ 945.5min
Epoch  48/100 â”‚ Loss: -0.9916 â”‚ Breast: 91.1% â”‚ 965.2min
Epoch  49/100 â”‚ Loss: -0.9918 â”‚ Breast: 91.1% â”‚ 984.5min
Epoch  50/100 â”‚ Loss: -0.9923 â”‚ Breast: 91.1% â”‚ 1005.5min
Epoch  51/100 â”‚ Loss: -0.9927 â”‚ Breast: 91.1% â”‚ 1026.8min
Epoch  52/100 â”‚ Loss: -0.9931 â”‚ Breast: 91.1% â”‚ 1047.9min
Epoch  53/100 â”‚ Loss: -0.9934 â”‚ Breast: 91.1% â”‚ 1068.6min
Epoch  54/100 â”‚ Loss: -0.9935 â”‚ Breast: 91.1% â”‚ 1088.0min
Epoch  55/100 â”‚ Loss: -0.9934 â”‚ Breast: 91.1% â”‚ 1107.5min
Epoch  56/100 â”‚ Loss: -0.9938 â”‚ Breast: 91.1% â”‚ 1126.9min
Epoch  57/100 â”‚ Loss: -0.9941 â”‚ Breast: 91.1% â”‚ 1146.4min
Epoch  58/100 â”‚ Loss: -0.9939 â”‚ Breast: 91.1% â”‚ 1166.0min
Epoch  59/100 â”‚ Loss: -0.9940 â”‚ Breast: 91.1% â”‚ 1185.4min
Epoch  60/100 â”‚ Loss: -0.9941 â”‚ Breast: 91.1% â”‚ 1205.1min
Epoch  61/100 â”‚ Loss: -0.9943 â”‚ Breast: 91.1% â”‚ 1224.5min
Epoch  62/100 â”‚ Loss: -0.9943 â”‚ Breast: 91.1% â”‚ 1244.2min
Epoch  63/100 â”‚ Loss: -0.9947 â”‚ Breast: 91.1% â”‚ 1264.3min
Epoch  64/100 â”‚ Loss: -0.9948 â”‚ Breast: 91.1% â”‚ 1284.2min
Epoch  65/100 â”‚ Loss: -0.9950 â”‚ Breast: 91.1% â”‚ 1304.5min
Epoch  66/100 â”‚ Loss: -0.9950 â”‚ Breast: 91.1% â”‚ 1324.4min
Epoch  67/100 â”‚ Loss: -0.9952 â”‚ Breast: 91.1% â”‚ 1344.1min
Epoch  68/100 â”‚ Loss: -0.9952 â”‚ Breast: 91.1% â”‚ 1363.6min
Epoch  69/100 â”‚ Loss: -0.9952 â”‚ Breast: 91.1% â”‚ 1383.0min
Epoch  70/100 â”‚ Loss: -0.9953 â”‚ Breast: 91.1% â”‚ 1402.5min
Epoch  71/100 â”‚ Loss: -0.9952 â”‚ Breast: 91.1% â”‚ 1422.0min
Epoch  72/100 â”‚ Loss: -0.9954 â”‚ Breast: 91.1% â”‚ 1441.5min
Epoch  73/100 â”‚ Loss: -0.9955 â”‚ Breast: 91.1% â”‚ 1460.9min
Epoch  74/100 â”‚ Loss: -0.9956 â”‚ Breast: 91.1% â”‚ 1480.2min
Epoch  75/100 â”‚ Loss: -0.9958 â”‚ Breast: 91.1% â”‚ 1499.7min
Epoch  76/100 â”‚ Loss: -0.9959 â”‚ Breast: 91.1% â”‚ 1519.0min
Epoch  77/100 â”‚ Loss: -0.9961 â”‚ Breast: 91.1% â”‚ 1538.1min
Epoch  78/100 â”‚ Loss: -0.9962 â”‚ Breast: 91.1% â”‚ 1557.5min
Epoch  79/100 â”‚ Loss: -0.9963 â”‚ Breast: 91.1% â”‚ 1576.9min
Epoch  80/100 â”‚ Loss: -0.9964 â”‚ Breast: 91.1% â”‚ 1598.7min
Epoch  81/100 â”‚ Loss: -0.9965 â”‚ Breast: 91.1% â”‚ 1620.1min
Epoch  82/100 â”‚ Loss: -0.9965 â”‚ Breast: 91.1% â”‚ 1642.1min
Epoch  83/100 â”‚ Loss: -0.9966 â”‚ Breast: 91.1% â”‚ 1661.4min
Epoch  84/100 â”‚ Loss: -0.9967 â”‚ Breast: 91.1% â”‚ 1681.0min
Epoch  85/100 â”‚ Loss: -0.9968 â”‚ Breast: 91.1% â”‚ 1700.6min
Epoch  86/100 â”‚ Loss: -0.9968 â”‚ Breast: 91.1% â”‚ 1720.8min
Epoch  87/100 â”‚ Loss: -0.9968 â”‚ Breast: 91.1% â”‚ 1740.7min
Epoch  88/100 â”‚ Loss: -0.9968 â”‚ Breast: 91.1% â”‚ 1761.1min
Epoch  89/100 â”‚ Loss: -0.9969 â”‚ Breast: 91.1% â”‚ 1781.9min
Epoch  90/100 â”‚ Loss: -0.9970 â”‚ Breast: 91.1% â”‚ 1802.1min
Epoch  91/100 â”‚ Loss: -0.9970 â”‚ Breast: 91.1% â”‚ 1822.0min
Epoch  92/100 â”‚ Loss: -0.9970 â”‚ Breast: 91.1% â”‚ 1841.7min
Epoch  93/100 â”‚ Loss: -0.9971 â”‚ Breast: 91.1% â”‚ 1861.4min
Epoch  94/100 â”‚ Loss: -0.9971 â”‚ Breast: 91.1% â”‚ 1880.9min
Epoch  95/100 â”‚ Loss: -0.9971 â”‚ Breast: 91.1% â”‚ 1900.3min
Epoch  96/100 â”‚ Loss: -0.9971 â”‚ Breast: 91.1% â”‚ 1921.2min
Epoch  97/100 â”‚ Loss: -0.9972 â”‚ Breast: 91.1% â”‚ 1942.4min
Epoch  98/100 â”‚ Loss: -0.9972 â”‚ Breast: 91.1% â”‚ 1963.1min
Epoch  99/100 â”‚ Loss: -0.9972 â”‚ Breast: 91.1% â”‚ 1984.8min
Epoch 100/100 â”‚ Loss: -0.9972 â”‚ Breast: 91.1% â”‚ 2005.4min

ğŸ¥ === MEDICAL-OPTIMIZED BYOL TRAINING COMPLETE ===
â±ï¸  Total training time: 33.4 hours
ğŸ’¾ Final model saved: mammogram_byol_final.pth
ğŸ“Š Dataset: 162,696 high-quality breast tissue tiles
ğŸ›¡ï¸  AGGRESSIVE background rejection: Zero empty space contamination
ğŸ›ï¸  Medical-safe augmentations: Preserves anatomical details
âš¡ A100 optimized: Mixed precision + per-step momentum updates
ğŸ¯ Ready for downstream fine-tuning and classification tasks
ğŸš€ Ready for downstream fine-tuning!
